{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd075386cb818e5218e21f8230aa12bc479745749892d35270ba19dd2e04b64604d",
   "display_name": "Python 3.7.4 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = r'\\', \\''\n",
    "frame_columns_names = [\"Тема обращения\",\"Суть обращения\",\n",
    "                        \"Чиновник\",\"Должность\",\n",
    "                        \"Дата подачи заявления\"]\n",
    "df = pd.read_csv('Mosru_dump_all_pages.csv',\n",
    "                    encoding = 'utf-8',\n",
    "                    sep = separator,\n",
    "                    names = None,\n",
    "                    skiprows = 1)\n",
    "df.columns = frame_columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    return re.sub('\\'','',string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_theme(string):\n",
    "    res = re.findall('«.*»',string)\n",
    "    return res[0] if len(res)>0 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_address(string):\n",
    "    res = re.findall('по адресу\\s?(.*$)',string)\n",
    "    return res[0] if len(res)>0 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingText(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\d+','',line,flags=re.UNICODE)#delete numbers\n",
    "    line = re.sub(r'[^\\w\\s]',' ',line,flags=re.UNICODE)\n",
    "    tl = nltk.word_tokenize(line) #tl - tokenize line\n",
    "    nft = [morph.parse(token)[0].normal_form for token in tl if len(token)>1]#nft - normal form token\n",
    "    clean_words_list = [normalToken for normalToken in nft if normalToken not in stop_words and len(normalToken)>1]#преобразованный список\n",
    "    return ' '.join(clean_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in frame_columns_names:\n",
    "    df[column] = df[column].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"theme\"] = df['Тема обращения'].apply(search_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"address\"] = df['Тема обращения'].apply(search_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Obr_clean'] = df['Суть обращения'].apply(preprocessingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_frame.csv',sep='|',encoding='utf-8')"
   ]
  },
  {
   "source": [
    "Вторая часть после загрузки и обработки данных"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.read_csv('clean_frame.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_addresses = n_df['address'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_token = \"your_mapbox_token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_district(address):\n",
    "    url = \"https://api.mapbox.com/geocoding/v5/mapbox.places/{0}.json?access_token={1}\".format(urllib.parse.quote(\"Москва \"+address), mapbox_token)\n",
    "    response = requests.get(url)\n",
    "    district = \"\"\n",
    "    try:\n",
    "        district = response.json()['features'][0]['place_name']\n",
    "    except Exception as error:\n",
    "        print(\"Возникла ошибка\"+str(error))\n",
    "    finally:\n",
    "        return district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for address in unique_addresses[123:129]:\n",
    "    print(search_district(address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}