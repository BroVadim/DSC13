{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0709df3ce15ab67dd2d8269f8dda0bdc6697ee9dab9ed0fbd8ba56f292f917ff1",
   "display_name": "Python 3.7.4 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = r'\\', \\''\n",
    "frame_columns_names = [\"Тема обращения\",\"Суть обращения\",\n",
    "                        \"Чиновник\",\"Должность\",\n",
    "                        \"Дата подачи заявления\"]\n",
    "df = pd.read_csv('Mosru_dump_all_pages.csv',\n",
    "                    encoding = 'utf-8',\n",
    "                    sep = separator,\n",
    "                    names = None,\n",
    "                    skiprows = 1)\n",
    "df.columns = frame_columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    dirt_patterns = ['\\'','\\\\n','\\n','\\\\\\\\/S+','\\\\\\\\','/\\S+','\\(.*\\)']\n",
    "    for pattern in dirt_patterns:\n",
    "        string = re.sub(pattern,'',string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_theme(string):\n",
    "    res = re.findall('«.*»',string)\n",
    "    return res[0] if len(res)>0 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_address(string):\n",
    "    res = re.findall('по адресу\\s?(.*$)',string)\n",
    "    return res[0] if len(res)>0 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingText(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\d+','',line,flags=re.UNICODE)#delete numbers\n",
    "    line = re.sub(r'[^\\w\\s]',' ',line,flags=re.UNICODE)\n",
    "    tl = nltk.word_tokenize(line) #tl - tokenize line\n",
    "    nft = [morph.parse(token)[0].normal_form for token in tl if len(token)>1]#nft - normal form token\n",
    "    clean_words_list = [normalToken for normalToken in nft if normalToken not in stop_words and len(normalToken)>1]#преобразованный список\n",
    "    return ' '.join(clean_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in frame_columns_names:\n",
    "    df[column] = df[column].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"theme\"] = df['Тема обращения'].apply(search_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"address\"] = df['Тема обращения'].apply(search_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Obr_clean'] = df['Суть обращения'].apply(preprocessingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_frame.csv',sep='|',encoding='utf-8')"
   ]
  },
  {
   "source": [
    "Вторая часть после загрузки и обработки данных (подтянуть адреса c помощью mapbox api)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.read_csv('clean_frame.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_addresses = n_df['address'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_token = \"pk.eyJ1IjoidmFkaW05NiIsImEiOiJja25nMGowN2QyNnFlMnFtdTkzYjBjejdkIn0.18dpTc8Vgja2gPDUYgrSkw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_district(address):\n",
    "    url = \"https://api.mapbox.com/geocoding/v5/mapbox.places/{0}.json?access_token={1}\".format(urllib.parse.quote(\"Москва \"+str(address)), mapbox_token)\n",
    "    response = requests.get(url)\n",
    "    district = \"\"\n",
    "    try:\n",
    "        district = response.json()['features'][0]['place_name']\n",
    "    except Exception as error:\n",
    "        print(\"Возникла ошибка-{0}, адрес - {1}\".format(str(error),str(address)) )\n",
    "    finally:\n",
    "        return district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_addresses_frame.csv','w',encoding='utf-8') as file:\n",
    "    file.write('Адрес|Полный ответ\\n')\n",
    "    for address in tqdm(unique_addresses):\n",
    "        full_response = search_district(address)\n",
    "        file.write('{0}|{1}\\n'.format(address,full_response))"
   ]
  },
  {
   "source": [
    "Схлестываем значения адресов с \"чистым фреймом\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_frame = pd.read_csv('unique_addresses_frame.csv',encoding='utf-8',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Тематическое моделирование"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_frame.csv',encoding='utf-8',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Obr_clean'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['Obr_clean'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words2 = [nltk.word_tokenize(str(line)) for line in tqdm(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data_words2)\n",
    "texts = data_words2\n",
    "#term document frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#количество тем\n",
    "num_topics = 10\n",
    "lda_model = gensim.models.LdaMulticore(corpus = corpus, id2word=id2word, num_topics = num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_prepared = pyLDA.gensim"
   ]
  }
 ]
}